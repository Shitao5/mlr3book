---
author:
  - name: Raphael Sonabend
    orcid: 0000-0001-9225-4654
    email: raphaelsonabend@gmail.com
    affiliations:
      - name: Imperial College London
  - name: Sebastian Fischer
    orcid: 0000-0002-9609-3197
    email: sebastian.fischer@stat.uni-muenchen.de
    affiliations:
      - name: Ludwig-Maximilians-Universität München
abstract: 
  TODO (150-200 WORDS)
---

# Implementing New Classes {#sec-extending}

{{< include _setup.qmd >}}

Hopefully having read the rest of this book you are now an `r mlr3` expert.
Maybe you will even want to extend the universe with new classes for more learners, measures, tasks, pipeops, tuners, filters, or more; if so, read on.

{{< include _optional.qmd >}}

In this chapter we will cover how to extend the two basic classes of the `r mlr3` universe: `r ref("Measure")` and `r ref("Learner")`.
We will start with extending measures (@sec-extending-measures) and then move on to learners (@sec-extending-learners), both in the context of regression, but this extends to any other machine learning task.
If you are interested in implementing new pipeops, tuners, feature selection methods, or filters, then check out the vignettes in the respective packages: `r mlr3pipelines`, `r mlr3tuning`, `r mlr3fselect`, or `r mlr3filters`.
Or if you are considering adding a new machine learning task then please contact us on GitHub, email, or Mattermost.

To understand this chapter, some basic familiarity with the `r ref_pkg("R6")` class system is required.
@sec-r6 contained a brief introduction and references to further resources.
This chapter does not contain information about e.g. coding-style, contribution guides, or other developer related information.
Such information can be found in the `r link("https://github.com/mlr-org/mlr3/wiki", "mlr3 Wiki")`.

We welcome contributions from all levels of developers and if you want to add any of your new classes to our universe then please make pull requests to aligning packages, for example tuners and filters would go to `r mlr3tuning` and `r mlr3filters` respectively, a new survival measure would go to `r mlr3proba`, and *all* new learners go to `r mlr3extralearners`.
Do not worry if you make a PR to the wrong repository, we will transfer it to the right one.

## Extending the Measure Class {#sec-extending-measures}

We will now turn to extending the `r ref("Measure")` class to implement new metrics, again we will focus on regression.
As an example, let's consider a regression measure that scores a prediction as $1$ if the difference between the true and predicted values are less than one standard deviation of the truth, or scores the prediction as $0$ otherwise.
In maths this would be defined as $f(y, \hat{y}) = \frac{\sum_{i=1}^n \mathbb{I}(|y_i - \hat{y}_i| < \sigma(y))}{n}$, where $y$ contains the true values and $\hat{y}$ the predicted values for observations $i = 1, ..., n$.
In code this may be written as:

```{r extending-015}
threshold_acc = function(truth, response) {
  score = numeric(length(truth))
  score[abs(truth - response) < sd(truth)] = 1
  mean(score)
}

threshold_acc(c(100, 0, 1), c(1, 11, 6))
```

This measure is then bounded in [0, 1] and a larger score is better.

To implement this measure, we need to create a new `r ref("R6::R6Class")`, which will inherit from `r ref("Measure")` and in this case specifically inheriting from `r ref("MeasureRegr")`.
We will now demonstrate what the final code for this new measure would look like and then explain each line, this can be used as a template for most performance measures.

```{r extending-016}
MeasureRegrThresholdAcc = R6::R6Class("MeasureRegrThresholdAcc", # class name
  inherit = mlr3::MeasureRegr, # regression measure
  public = list(
    initialize = function() { # initialize class
      super$initialize(
        id = "thresh_acc", # unique ID
        packages = character(), # no dependencies
        properties = character(), # no special properties
        predict_type = "response", # measures response prediction
        range = c(0, 1), # results in values between (0, 1)
        minimize = FALSE # larger values are better
      )
    }
  ),

  private = list(
    .score = function(prediction, ...) { # define score as private method
      # define loss
      threshold_acc = function(truth, response) {
        score = numeric(length(truth))
        score[abs(truth - response) < sd(truth)] = 1
        mean(score)
      }
      # call loss function
      threshold_acc(prediction$truth, prediction$response)
    }
  )
)
```

1. In the first two lines we name the class, here "MeasureMSE", and then state this is a regression measure and inherits from `r ref("MeasureRegr")`.
2. We initialize the class by stating its unique ID is "thresh_acc", that it does not require any external packages (`packages = character()`) and that it has no special properties (`properties = character()`).
3. We then pass specific details of the loss function which are: it measures the quality of a "response" type prediction, its values range between (0, 1), and that the loss is optimised as its maximum.
4. Finally we define the score itself as a private method called `.score` and simply pass the predictions to the function we defined earlier.

Sometimes measures require data from the training set, the task, or the learner.
These are usually complex edge-cases examples so we will not go into detail here, for working examples look at the code for `r ref("mlr3proba::MeasureSurvSongAUC")` and `r ref("mlr3proba::MeasureSurvAUC")`.
Furthermore, you can consult the manual page of the `r ref("Measure")` for an overview of other properties and meta-data that can be specified.

Once you have defined your measure you can either use it with the `R6` constructor, or by adding it to the `r ref("mlr_measures")` dictionary:

```{r}
library(mlr3verse)

t = tsk("mtcars")
s = partition(t)
p = lrn("regr.rpart")$train(t, s$train)$predict(t, s$test)
p$score(MeasureRegrThresholdAcc$new())

# or add to dictionary
mlr3::mlr_measures$add("regr.thresh_acc", MeasureRegrThresholdAcc)
p$score(msr("regr.thresh_acc"))
```

## Extending the Learner Class {#sec-extending-learners}

Although many learners are already included in the `r mlr3` ecosystem, there might be a situation in which your algorithm of choice is not implemented.
Here, we show how to create a custom `r ref("Learner")` by reimplementing the `regr.rpart` learner from `r mlr3`.

:::{.callout-tip}
The `r ref("mlr3extralearner::create_learner")` function can be used to generate files containing templates for the learner and test files.
We will not use it in this book chapter for the sake of clarity, but recommend using it in practice to avoid writing a lot of boilerplate code.
:::


In case you not only want to create the learner for personal use, but also add it to `r mlr3extralearners`, please consult its `r link("", "extending vignette (TODO)")`.

Creating a new learner class consists of: 

1. Picking the right mlr3 class to inherit from
1. Calling the `$initialize()` method of the parent class with the right meta-information. 
  This includes defining its parameter set.
1. Adding missing private and public methods, most importantly  `$.train()` and `$.predict()`.
1. Testing the correctness of the learner.

We start with showing the code and will then explain it.
In a slightly unusual fashion, we will not write down the learner class in one go, but incrementally add the methods using the `$set()` class method.
This is purely for didactic reasons.

```{r}
LearnerRegrRpart2 = R6::R6Class("LearnerRegrRpart2",
  inherit = LearnerRegr,
  public = list(
    initialize = function() {
      param_set = ps(
        cp             = p_dbl(0, 1, default = 0.01, tags = "train"),
        keep_model     = p_lgl(default = FALSE, tags = "train"),
        maxcompete     = p_int(0L, default = 4L, tags = "train"),
        maxdepth       = p_int(1L, 30L, default = 30L, tags = "train"),
        maxsurrogate   = p_int(0L, default = 5L, tags = "train"),
        minbucket      = p_int(1L, tags = "train"),
        minsplit       = p_int(1L, default = 20L, tags = "train"),
        surrogatestyle = p_int(0L, 1L, default = 0L, tags = "train"),
        usesurrogate   = p_int(0L, 2L, default = 2L, tags = "train"),
        xval           = p_int(0L, default = 10L, tags = "train")
      ) 
      param_set$values$xval = 10
      super$initialize(
        id = "regr.rpart2",
        feature_types = c("logical", "integer", "numeric", "factor", "ordered"),
        predict_types = "response",
        packages = "rpart",
        param_set = param_set,
        properties = c("weights", "missings", "importance", "selected_features"),
        label = "Regression Tree",
        man = "mlr3::mlr_learners_regr.rpart"
      )
    }
  )
)
```

We first specify the class name according to the mlr3 naming convention as "LearnerRegrRpart2".
In the second line, we select the appropriate parent class from which we want to inherit.
Because we are implementing a regression learner, we have to inherit from the `r ref("LearnerRegr")` class.
For classification we would inherit from `r ref("LearnerClassif")`, for survival from `r ref("LearnerSurv")`, and for clustering from `r ref("LearnerClust")`.

In the constructor, the constructor of the super class (in this case `r ref("LearnerRegr")`) is called with meta information about the learner which should be constructed.
We strongly recommend reading the relevant class documentation to understand its arguments.
This includes:

* `id`: The ID of the new learner. 
* `packages`: The upstream package name(s) of the implemented learner.
* `param_set`: A set of hyperparameters and their descriptions provided as a `r ref("paradox::ParamSet")`.
* `predict_types`: Set of predict types the learner supports.
  See `mlr_reflections$learner_predict_types`.
* `feature_types`: Set of feature types the learner is able to handle.
  See `mlr_reflections$task_feature_types`.
* `properties`: Set of properties of the learner. 
  See `mlr_reflections$learner_properties`.
* `man`: The roxygen identifier of the learner.
  This is used within the `$help()` method of the super class to open the help page of the learner.
* `label`: The label of the learner.
  This should briefly describe the learner (similar to the description's title) and is for example used for printing.

To fill some oft this meta-information, one has to go through the manual pages of the upstream package.
It is a good idea, to look at already existing learners for inspiration on how implement a new class and conventions that we follow.

### Defining the Parameter Set of a Learner {#sec-extending-learners-ps}

The parameter set of a learner is the set of hyperparameters used in model training and predicting, this is given as a `r ref("paradox::ParamSet")`.
The set consists of a list of hyperparameters, where each has a specific class for the hyperparameter type, see (TODO: section in fundamentals).
For the most part, creating a parameter set for a learner works analogously to creating search spaces, which we have already covered in (TODO:).
However, there are some aspects of parameters that we have not covered so far.
These are:

* **tags** that organize the parameters, e.g. whether they are used during training or prediction
* **default values** which give information about the value that is used when no value is set
* **initial values** are simply the parameter set's `$values` that can be set after construction
* **custom checks** which allow to specify custom constraints for untyped parameters (`r ref("ParamUty")`)


**Tags**

Each parameter has one or more tags, that determine in which method they are used.
I.e. parameters that are used during training must be tagged with `"train"` and those that are used during prediction with `"predict"`.
Parameters with certain tags, can be retrieved by calling the `$get_values()` method of a `r ref("ParamSet")` with the `tag` argument, which will be useful later, when implementing the train and predict methods.

Furthermore, there are other tags that serve specific purposes:

* The tag `"threads"` should be used (if applicable) to tag the parameter that determines the number of threads used for the learner's internal parallelization.
  Once a learner is constructed, this parameter can be set using `r ref("set_threads")`.
* The tag `"required"` should be used to tag parameters that must be provided for the algorithm to be executable.

**Default Values**

The default values of each parameter indicate which value the upstream function (in this case `r ref("rpart::rpart")`) uses if no parameter is specified.
These have to be retrieved from the package's documentation.
If parameters have no default, they have to tagged with the `"required"` tag.
For such parameters, we recommended to initialize the parameter to a value in the initialize method, so that the learner can be executed after creation.
Note that setting a parameter value in the `$initialize()` method does not change the parameter's default value, c.f. (TODO: Section fundamentals(?) or add it here).

Note that parameters expect the default values to be of their respective type, e.g. the default of `r ref("ParamInt")` must be an integer.
Some packages have R expressions as default values which cannot be properly expressed in `r paradox`.
In such a case, a practical compromise is to not set any default value when calling `r ref("paradox::p_int")`.

**Initial Values**

In some rare cases you may want to change the parameter values during initialization.
You can do this by changing the `param_set$values` during the learner's construction.
You can see we have done this for `"regr.rpart"` where the default for `xval` is changed to `0`.
Note that the default in the `r ref("ParamSet")` is recorded as our changed default (0), and not the original (10).
It is strongly recommended to only change the defaults if absolutely required, when this is the case add the following to the learner documentation:
Note however that we still annotate the default of the `xval` parameter as 0.
For a difference between initial parameter values and default values see (TODO: Fundamentals (?)).

**Custom Checks**

In `r ref_pkg("paradox")` only integers, numerics, factors, and logicals have their own parameter types.
For all other parameters, the `r ref("ParamUty")` has to be used, which is constructed through the `r ref("p_uty")` function.
It has the argument `custom_check` function, which allows to specify custom constraints.
Must return `TRUE` if the input is valid and a `character(1)` with the error message otherwise. 


###  Train function {#sec-learner-train}

The train function takes a `r ref("Task")` as input and must return a model.
Let's say we want to translate the following call of `rpart::rpart()` into code that can be used inside the `.train()` method.

First, we write something down that works completely without `r mlr3`:

```{r extending-006,eval=TRUE}
data = mtcars
model = rpart::rpart(mpg ~ ., data = mtcars, xval = 0)
```

We need to pass the formula notation `mpg ~ .`, the data and the hyperparameters.
To get the hyperparameters, we call `self$param_set$get_values(tag = "train")` and thereby query all parameters that are using during `"train"`.
Then, the dataset is extracted from the `r ref("Task")`.
Because the learner has the property `"weights"`, we insert the weights of the task if there are any.

Last, we call the upstream function `rpart::rpart()` with the data and pass all hyperparameters via argument `.args` using the `r ref("mlr3misc::invoke()")` function.
The latter is simply an optimized version of `do.call()` that we use within the `r mlr3` ecosystem.

```{r extending-007,eval=TRUE}
.train = function(task) {
  pv = self$param_set$get_values(tags = "train")
  if ("weights" %in% task$properties) {
    pv$weights = task$weights$weight
  }
  formula = task$formula()
  data = task$data()
  mlr3misc::invoke(
    rpart::rpart,
    formula = formula,
    data = data,
    .args = pv
  )
}
LearnerRegrRpart2$set("private", ".train", .train)
```

### Predict function {#sec-learner-predict}

The internal predict method `.predict()` also operates on a `r ref("Task")` as well as on the fitted model that has been created by the `$train()` call previously and has been stored in `self$model`.

The return value is a `r ref("Prediction")` object.
We proceed analogously to what we did in the previous section.
We start with a version without any `r mlr3` objects and continue to replace objects until we have reached the desired interface:

```{r extending-008,eval=TRUE}
# inputs:
#| cache: false
task = tsk("mtcars")
self = list(model = rpart::rpart(task$formula(), data = task$data()))

data = mtcars
response = predict(self$model, newdata = data)
```

The `"rpart::predict.rpart()"` function predicts class labels if argument `type` is set to to `"class"`, and class probabilities if set to `"prob"`.

Next, we transition from `data` to a `r ref("Task")` again and construct a list with the return type requested by the user, this is stored in the `$predict_type` slot of a learner class. Note that the `r ref("Task")` is automatically passed to the prediction object, so all you need to do is return the predictions! Make sure the list names are identical to the task predict types.

The final `.predict()` method is below, we could omit the `pars` line as there are no parameters with the `"predict"` tag but we keep it here to be consistent:

```{r extending-009}
#| cache: false
.predict = function(task) {
  pv = self$param_set$get_values(tags = "predict")
  # ensure same column order in train and predict
  newdata = task$data(cols = intersect(names(learner$state$data_prototype), task$feature_names))
  response = mlr3misc::invoke(predict, self$model, newdata = newdata, .args = pv)
  list(response = unname(response))
}

LearnerRegrRpart2$set("private", ".predict", .predict)
```

:::{.callout-warning}
You cannot rely on the column order of the data returned by `task$data()` as the order of columns may be different from the order of the columns during `$.train`.
The `newdata` line ensures the ordering is the same by calling the same order as in train!
:::

### Optional Extractors {#sec-optional-extractors}

Specific learner implementations are free to implement additional getters to ease the access of certain parts of the model in the inherited subclasses.
Some of these methods are standardized in `r mlr3`, c.f. the `r ref("Learner")` documentation.
Because we specified earlier that the learner has the properties "weights" and "selected_feature", we implement these (standardized) extractors as public method.
They access the `$model` slot of a learner after training and return one if its field.
If it is one of the standardized extractors, some custom code might have to be written. 
E.g. the `$importance()` method must return the importance scores as a sorted numeric vector, the names being the features.

```{r, cache = FALSE}
importance = function() {
  if (is.null(self$model)) {
    stopf("No model stored")
  }
  if (!is.null(self$model$variable.importance)) {
    self$model$variable.importance
  } else {
    mlr3misc::set_names(numeric(), decreasing = TRUE)
  }
}

LearnerRegrRpart2$set("public", "importance", importance)
```

The selected features must return a subset of the features that were selected internally by the learning algorithm.

```{r, cache = FALSE}
selected_features = function() {
  if (is.null(self$model)) {
    stopf("No model stored")
  }
  setdiff(self$model$frame$var, "<leaf>")
}
LearnerRegrRpart2$set("public", "selected_features", selected_features)
```

### Testing the learner {#sec-learner-test}

Once your learner is created, you should write tests to verify its correctness.
Besides manual tests, the `r mlr3` package also provides automatic tests to check that a learner satisfies some basic sanity checks and that it implements all the available parameters of the upstream function.

For a bare-bone check you can just try to run a simple `$train()` call locally.

```{r extending-012, eval = TRUE}
task = tsk("mtcars") # assuming a Classif learner
learner = LearnerRegrRpart2$new()
learner$train(task)
p = learner$predict(task)
p$confusion

learner$importance()
learner$selected_features()
```

If it runs without erroring, that's a very good start!

#### Autotest {#sec-learner-test-unit}

To ensure that your learner is able to handle all kinds of different properties and feature types, we have written an "autotest" that checks the learner for different combinations of such.
These are defined in the helper files in the `inst` directories of the repositories and can be loaded as follows.

TODO: This is too ugly
```{r}
#| output: false
lapply(list.files(system.file("testthat", package = "mlr3"), pattern = "^helper.*\\.[rR]", full.names = TRUE), source)
lapply(list.files(system.file("testthat", package = "mlr3proba"), pattern = "^helper.*\\.[rR]", full.names = TRUE), source)

```

```{r}
#| cache: false
#| output: false
#| echo: false
library(testthat)
```


```{r extending-013, eval = TRUE}
#| error: true
library(testthat)
test_that("autotest", {
  learner = LearnerRegrRpart2$new()
  # TODO: Re-enable this when it is possible to disable the man page check

  # expect_learner(learner)
  # note that you can skip tests using the exclude argument
  result = run_autotest(learner)
  expect_true(result, info = result$error)
})
```

For some learners that have required parameters, it is needed to set some values for required parameters after construction so that the learner can be run in the first place.

You can also exclude some specific test arrangements within the "autotest" via the argument `exclude` in the `run_autotest()` function.
Currently the `run_autotest()` function lives in [inst/testthat](https://github.com/mlr-org/mlr3/blob/f16326bf34bcac59c3b0a2fdbcf90dbebb3b4bbc/inst/testthat/helper_autotest.R) of the `r mlr3` and still lacks documentation.
This should change in the near future.

#### Checking Parameters {#sec-learner-test-parameter}

Some learners have a high number of parameters and it is easy to miss out on some during the creation of a new learner.
Therefore we have written a "Parameter Check" that runs regularly for every learner.
This "Parameter Check" compares the parameters of the `r mlr3` ParamSet against all arguments available in the upstream function that is called during `$train()` and `$predict()`.
When the `.train` function calls multiple functions (e.g. a control function as described above), a list of functions can be passed to the parameter test.

The test comes with an `exclude` argument that should be used to _exclude and explain_ why certain arguments of the upstream function are not within the ParamSet of the mlr3learner.
This will likely be required for all learners as common arguments like `x`, `target` or `data` are handled by the `r mlr3` interface and are therefore not included within the ParamSet.

However, there might be more parameters that need to be excluded, for example:

* Type dependent parameters, i.e. parameters that only apply for classification or regression learners.
* Parameters that are actually deprecated by the upstream package and which were therefore not included in the `r mlr3` ParamSet.

All excluded parameters should have a comment justifying their exclusion.

In our example, the final paramtest script looks like:

```{r extending-014, eval = TRUE}
#| error: true
test_that("LearnerRegrRpart2 train", {
  learner = LearnerRegrRpart2$new()
  # this can also be a list of functions
  fun = rpart::rpart
  exclude = c(
    "formula", # handled internally
    "model", # handled internally
    "data", # handled internally
    "weights", # handled by task
    "subset", # handled by task
    "na.action", # handled internally
    "method", # handled internally
    "x", # handled internally
    "y", # handled internally
    "parms", # handled internally
    "control", # handled internally
    "cost" # handled internally
  )

  paramtest = run_paramtest(learner, fun, exclude, tag = "train")
  expect_true(paramtest, info = paramtest$error)
})

test_that("LearnerRegrRpart2 predict", {
  learner = LearnerRegrRpart2$new()
  fun = rpart:::newdata = predict.rpart
  exclude = c(
    "object", # handled internally
    "newdata", # handled internally
    "type", # handled internally
    "na.action" # handled internally
  )

  paramtest = run_paramtest(learner, fun, exclude, tag = "predict")
  expect_true(paramtest, info = paramtest$error)
})
```

## Conclusion

In this final chapter we looked at how to implement new learners and measures using the language of `r mlr3`.
If you want to learn more about implementing new classes, we recommend familiarising yourself fully with `R6` and reading source code across different packages in the `mlr3verse`.
We have not included exercises in this chapter but encourage you to play with the source code to try and implement new classes yourself.
If you want help whilst implementing a new learner or measure, please reach out and we would be very happy to support you.
If you are considering implementing a new machine learning task, please get in touch by email, GitHub, or Mattermost, and we would be happy to chat about your plans.
